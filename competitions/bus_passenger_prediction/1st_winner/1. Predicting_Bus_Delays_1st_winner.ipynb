{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#라이브러리-및-데이터\" data-toc-modified-id=\"라이브러리-및-데이터-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>라이브러리 및 데이터</a></span><ul class=\"toc-item\"><li><span><a href=\"#Library-&amp;-Data\" data-toc-modified-id=\"Library-&amp;-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Library &amp; Data</a></span></li><li><span><a href=\"#Crawling-Code\" data-toc-modified-id=\"Crawling-Code-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Crawling Code</a></span></li></ul></li><li><span><a href=\"#데이터-전처리\" data-toc-modified-id=\"데이터-전처리-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>데이터 전처리</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-Cleansing-&amp;-Pre-Processing\" data-toc-modified-id=\"Data-Cleansing-&amp;-Pre-Processing-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Data Cleansing &amp; Pre-Processing</a></span></li></ul></li><li><span><a href=\"#탐색적-자료분석\" data-toc-modified-id=\"탐색적-자료분석-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>탐색적 자료분석</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Exploratory Data Analysis</a></span></li></ul></li><li><span><a href=\"#변수-선택-및-모델-구축\" data-toc-modified-id=\"변수-선택-및-모델-구축-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>변수 선택 및 모델 구축</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feature-Engineering-&amp;-Evaluation\" data-toc-modified-id=\"Feature-Engineering-&amp;-Evaluation-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Feature Engineering &amp; Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#weekday\" data-toc-modified-id=\"weekday-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>weekday</a></span></li><li><span><a href=\"#route_station\" data-toc-modified-id=\"route_station-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>route_station</a></span></li><li><span><a href=\"#bus_route_id_weekday\" data-toc-modified-id=\"bus_route_id_weekday-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>bus_route_id_weekday</a></span></li><li><span><a href=\"#station_code_weekday\" data-toc-modified-id=\"station_code_weekday-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>station_code_weekday</a></span></li><li><span><a href=\"#route_station_weekday\" data-toc-modified-id=\"route_station_weekday-4.1.5\"><span class=\"toc-item-num\">4.1.5&nbsp;&nbsp;</span>route_station_weekday</a></span></li><li><span><a href=\"#on_time\" data-toc-modified-id=\"on_time-4.1.6\"><span class=\"toc-item-num\">4.1.6&nbsp;&nbsp;</span>on_time</a></span></li><li><span><a href=\"#승-하차-시간대-통합-변수-(t-~-t+2)\" data-toc-modified-id=\"승-하차-시간대-통합-변수-(t-~-t+2)-4.1.7\"><span class=\"toc-item-num\">4.1.7&nbsp;&nbsp;</span>승 하차 시간대 통합 변수 (t ~ t+2)</a></span></li><li><span><a href=\"#Make-features-by-using-target-variable\" data-toc-modified-id=\"Make-features-by-using-target-variable-4.1.8\"><span class=\"toc-item-num\">4.1.8&nbsp;&nbsp;</span>Make features by using target variable</a></span></li><li><span><a href=\"#congestion\" data-toc-modified-id=\"congestion-4.1.9\"><span class=\"toc-item-num\">4.1.9&nbsp;&nbsp;</span>congestion</a></span></li><li><span><a href=\"#location\" data-toc-modified-id=\"location-4.1.10\"><span class=\"toc-item-num\">4.1.10&nbsp;&nbsp;</span>location</a></span></li><li><span><a href=\"#merge-key\" data-toc-modified-id=\"merge-key-4.1.11\"><span class=\"toc-item-num\">4.1.11&nbsp;&nbsp;</span>merge key</a></span></li><li><span><a href=\"#오전-시간의-여러-데이터-활용한-변수\" data-toc-modified-id=\"오전-시간의-여러-데이터-활용한-변수-4.1.12\"><span class=\"toc-item-num\">4.1.12&nbsp;&nbsp;</span>오전 시간의 여러 데이터 활용한 변수</a></span></li><li><span><a href=\"#배차-간격\" data-toc-modified-id=\"배차-간격-4.1.13\"><span class=\"toc-item-num\">4.1.13&nbsp;&nbsp;</span>배차 간격</a></span></li><li><span><a href=\"#Label-encoding-feature\" data-toc-modified-id=\"Label-encoding-feature-4.1.14\"><span class=\"toc-item-num\">4.1.14&nbsp;&nbsp;</span>Label encoding feature</a></span></li><li><span><a href=\"#weather\" data-toc-modified-id=\"weather-4.1.15\"><span class=\"toc-item-num\">4.1.15&nbsp;&nbsp;</span>weather</a></span></li><li><span><a href=\"#weekday-(data)\" data-toc-modified-id=\"weekday-(data)-4.1.16\"><span class=\"toc-item-num\">4.1.16&nbsp;&nbsp;</span>weekday (data)</a></span></li><li><span><a href=\"#in---out\" data-toc-modified-id=\"in---out-4.1.17\"><span class=\"toc-item-num\">4.1.17&nbsp;&nbsp;</span>in - out</a></span></li><li><span><a href=\"#좌표데이터를-이용-변수\" data-toc-modified-id=\"좌표데이터를-이용-변수-4.1.18\"><span class=\"toc-item-num\">4.1.18&nbsp;&nbsp;</span>좌표데이터를 이용 변수</a></span></li><li><span><a href=\"#출근-시간의-총-승객-수\" data-toc-modified-id=\"출근-시간의-총-승객-수-4.1.19\"><span class=\"toc-item-num\">4.1.19&nbsp;&nbsp;</span>출근 시간의 총 승객 수</a></span></li><li><span><a href=\"#날짜-및-시간대-별-총-승객수\" data-toc-modified-id=\"날짜-및-시간대-별-총-승객수-4.1.20\"><span class=\"toc-item-num\">4.1.20&nbsp;&nbsp;</span>날짜 및 시간대 별 총 승객수</a></span></li><li><span><a href=\"#주말,-주중\" data-toc-modified-id=\"주말,-주중-4.1.21\"><span class=\"toc-item-num\">4.1.21&nbsp;&nbsp;</span>주말, 주중</a></span></li><li><span><a href=\"#연휴\" data-toc-modified-id=\"연휴-4.1.22\"><span class=\"toc-item-num\">4.1.22&nbsp;&nbsp;</span>연휴</a></span></li><li><span><a href=\"#요일-별-평균-승객-수\" data-toc-modified-id=\"요일-별-평균-승객-수-4.1.23\"><span class=\"toc-item-num\">4.1.23&nbsp;&nbsp;</span>요일 별 평균 승객 수</a></span></li><li><span><a href=\"#시내-및-시외버스-별-평균-탑승-승객\" data-toc-modified-id=\"시내-및-시외버스-별-평균-탑승-승객-4.1.24\"><span class=\"toc-item-num\">4.1.24&nbsp;&nbsp;</span>시내 및 시외버스 별 평균 탑승 승객</a></span></li><li><span><a href=\"#카테고리별-승객-수\" data-toc-modified-id=\"카테고리별-승객-수-4.1.25\"><span class=\"toc-item-num\">4.1.25&nbsp;&nbsp;</span>카테고리별 승객 수</a></span></li><li><span><a href=\"#Category별-승객의-비율\" data-toc-modified-id=\"Category별-승객의-비율-4.1.26\"><span class=\"toc-item-num\">4.1.26&nbsp;&nbsp;</span>Category별 승객의 비율</a></span></li><li><span><a href=\"#각-동,읍,면별-직업군별-비율,-평균소득액,-평균소비액\" data-toc-modified-id=\"각-동,읍,면별-직업군별-비율,-평균소득액,-평균소비액-4.1.27\"><span class=\"toc-item-num\">4.1.27&nbsp;&nbsp;</span>각 동,읍,면별 직업군별 비율, 평균소득액, 평균소비액</a></span></li><li><span><a href=\"#수요가-많을-것으로-예상되는-정류장\" data-toc-modified-id=\"수요가-많을-것으로-예상되는-정류장-4.1.28\"><span class=\"toc-item-num\">4.1.28&nbsp;&nbsp;</span>수요가 많을 것으로 예상되는 정류장</a></span></li><li><span><a href=\"#동---라벨인코딩\" data-toc-modified-id=\"동---라벨인코딩-4.1.29\"><span class=\"toc-item-num\">4.1.29&nbsp;&nbsp;</span>동 - 라벨인코딩</a></span></li><li><span><a href=\"#측정소와-정류장-사이-거리-계산\" data-toc-modified-id=\"측정소와-정류장-사이-거리-계산-4.1.30\"><span class=\"toc-item-num\">4.1.30&nbsp;&nbsp;</span>측정소와 정류장 사이 거리 계산</a></span></li><li><span><a href=\"#날씨-관련-변수\" data-toc-modified-id=\"날씨-관련-변수-4.1.31\"><span class=\"toc-item-num\">4.1.31&nbsp;&nbsp;</span>날씨 관련 변수</a></span></li><li><span><a href=\"#rainy_day\" data-toc-modified-id=\"rainy_day-4.1.32\"><span class=\"toc-item-num\">4.1.32&nbsp;&nbsp;</span>rainy_day</a></span></li><li><span><a href=\"#승-하차-시간대-통합-변수-(t-~-t+3)\" data-toc-modified-id=\"승-하차-시간대-통합-변수-(t-~-t+3)-4.1.33\"><span class=\"toc-item-num\">4.1.33&nbsp;&nbsp;</span>승 하차 시간대 통합 변수 (t ~ t+3)</a></span></li></ul></li><li><span><a href=\"#Make-dataset\" data-toc-modified-id=\"Make-dataset-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Make dataset</a></span></li><li><span><a href=\"#Columns\" data-toc-modified-id=\"Columns-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Columns</a></span></li></ul></li><li><span><a href=\"#모델-학습-및-검증\" data-toc-modified-id=\"모델-학습-및-검증-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>모델 학습 및 검증</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task---0\" data-toc-modified-id=\"Task---0-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Task - 0</a></span></li><li><span><a href=\"#Task---1\" data-toc-modified-id=\"Task---1-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Task - 1</a></span></li><li><span><a href=\"#Task---2\" data-toc-modified-id=\"Task---2-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Task - 2</a></span></li><li><span><a href=\"#Task---3\" data-toc-modified-id=\"Task---3-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Task - 3</a></span></li><li><span><a href=\"#Task---4\" data-toc-modified-id=\"Task---4-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Task - 4</a></span></li><li><span><a href=\"#Ensemble\" data-toc-modified-id=\"Ensemble-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Ensemble</a></span><ul class=\"toc-item\"><li><span><a href=\"#변수별-성능-및-상관관계-확인\" data-toc-modified-id=\"변수별-성능-및-상관관계-확인-5.6.1\"><span class=\"toc-item-num\">5.6.1&nbsp;&nbsp;</span>변수별 성능 및 상관관계 확인</a></span></li><li><span><a href=\"#멱평균\" data-toc-modified-id=\"멱평균-5.6.2\"><span class=\"toc-item-num\">5.6.2&nbsp;&nbsp;</span>멱평균</a></span><ul class=\"toc-item\"><li><span><a href=\"#첫-번-째-조합\" data-toc-modified-id=\"첫-번-째-조합-5.6.2.1\"><span class=\"toc-item-num\">5.6.2.1&nbsp;&nbsp;</span>첫 번 째 조합</a></span></li><li><span><a href=\"#두-번-째-조합\" data-toc-modified-id=\"두-번-째-조합-5.6.2.2\"><span class=\"toc-item-num\">5.6.2.2&nbsp;&nbsp;</span>두 번 째 조합</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#결과-및-제언\" data-toc-modified-id=\"결과-및-제언-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>결과 및 제언</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conclusion-&amp;-Discussion\" data-toc-modified-id=\"Conclusion-&amp;-Discussion-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Conclusion &amp; Discussion</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2oNIeGn8lZG"
   },
   "source": [
    "###### Dacon  13회 Jeju BigData Competition 모델링 경진대회\n",
    "###### 제주감귤\n",
    "###### 2019년 12월 8일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "n9y2ibf_8lZG"
   },
   "source": [
    "###### 모델링 코드 작성방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "s6MsrKfk8lZH"
   },
   "source": [
    "A 코드 관련\n",
    "\n",
    "1) 입상자는 코드 제출 필수. 제출 코드는 예측 결과를 리더보드 점수로 복원할 수 있어야 함\n",
    "\n",
    "2) 코드 제출시 확장자가 R user는 R or .rmd. Python user는 .py or .ipynb\n",
    "\n",
    "3) 코드에 ‘/data’ 데이터 입/출력 경로 포함 제출 or R의 경우 setwd(\" \"), python의 경우 os.chdir을 활용하여 경로 통일\n",
    "\n",
    "4) 전체 프로세스를 일목요연하게 정리하여 주석을 포함하여 하나의 파일로 제출\n",
    "\n",
    "5) 모든 코드는 오류 없이 실행되어야 함(라이브러리 로딩 코드 포함되어야 함).\n",
    "\n",
    "6) 코드와 주석의 인코딩은 모두 UTF-8을 사용하여야 함\n",
    "\n",
    " \n",
    "B 외부 데이터 관련\n",
    "\n",
    "1) 외부 공공 데이터 (날씨 정보 등) 사용이 가능하나, 코드 제출 시 함께 제출\n",
    "\n",
    "2) 공공 데이터 외의 외부 데이터는 법적인 제약이 없는 경우에만 사용 가능\n",
    "\n",
    "3) 외부 데이터를 크롤링할 경우, 크롤링 코드도 함께 제출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llZT-ZR08lZI"
   },
   "source": [
    "## 라이브러리 및 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sOqbRnD-8lZJ"
   },
   "outputs": [],
   "source": [
    "# base\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# data preprocessing\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', 130, 'max_rows', 30)\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "plt.rc('axes', unicode_minus=False)\n",
    "\n",
    "# ignore warining\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import folium # 지도 관련 시각화\n",
    "from folium.plugins import MarkerCluster #지도 관련 시각화\n",
    "import geopy.distance #거리 계산해주는 패키지 사용\n",
    "\n",
    "\n",
    "# save\n",
    "from sklearn.externals import joblib \n",
    "import pickle\n",
    "\n",
    "# selenium\n",
    "from selenium.webdriver import Chrome\n",
    "\n",
    "import geopy.distance\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.externals import joblib \n",
    "import pickle\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from keras import metrics\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n7034hw6_ZT9"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "bts = pd.read_csv(\"bus_bts.csv\")\n",
    "\n",
    "train.shape, test.shape, bts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_YwLQuG_ZUF"
   },
   "source": [
    "### Crawling Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `기상청 날씨누리` 사이트에서 지상 관측 자료를 크롤링 함\n",
    "* http://www.weather.go.kr/\n",
    "* 중급자 코드가 올라오기 전에 수행 함\n",
    "* 중급자 코드에서 weather.csv를 만드는 코드가 있는데 제주감귤팀이 제출한 weather.csv는 이 크롤링을 통해 만들어진 것이고, 중급자 코드에 해당하는 weather.csv가 아님\n",
    "* chromedriver.exe를 작업 경로에 위치시켜야 함\n",
    "* 2019년 9월 1일부터 2019년 10월 16일 까지의 데이터를 크롤링하였으며, 오전 10시의 관측 데이터만 사용하였기 때문에 data leakage에 해당하지 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_weather() :\n",
    "    \n",
    "    weather_data_10 = pd.DataFrame(columns=['현재일기_10','현재기온_10','체감온도_10','일강수_10'])\n",
    "    browser = Chrome()\n",
    "    url = 'http://www.weather.go.kr/weather/observation/currentweather.jsp?auto_man=m&type=t99&reg=184&tm=2019.10.25.16%3A00&x=19&y=7'\n",
    "    browser.get(url)\n",
    "\n",
    "    for i in range(0,46):\n",
    "        i+=1\n",
    "\n",
    "        elem=browser.find_element_by_id('observation_text')\n",
    "        elem.clear()\n",
    "        elem.send_keys(\"2019.9.{}.10:00\".format(i))\n",
    "\n",
    "        btn=browser.find_elements_by_class_name('btn')\n",
    "        btn[2].click()\n",
    "        \n",
    "        time.sleep(1)\n",
    "        weathers = browser.find_elements_by_css_selector('td')\n",
    "        weather_data_10 = weather_data_10.append(pd.DataFrame([[weathers[40].text,weathers[44].text, weathers[46].text, weathers[47].text]],columns=['현재일기_10','현재기온_10','체감온도_10','일강수_10']))\n",
    "        \n",
    "            \n",
    "    print('success !')\n",
    "    browser.close()\n",
    "    \n",
    "    return weather_data_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = crawl_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.to_csv('weather.csv', index = False)\n",
    "\n",
    "print('save.. !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p2myNvfI_ZUH"
   },
   "source": [
    "### Data Cleansing & Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02wYXbxE_ZUN"
   },
   "source": [
    "## 탐색적 자료분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJ5_KA6h_ZUN"
   },
   "source": [
    "## 변수 선택 및 모델 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['weekday'] = train['date'].dt.weekday\n",
    "\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['weekday'] = test['date'].dt.weekday\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### route_station"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "route_station = bus_route_id + station_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bus_route_id'] = train['bus_route_id'].astype(str)\n",
    "train['station_code'] = train['station_code'].astype(str)\n",
    "train['route_station'] = train['bus_route_id'] + ',' + train['station_code']\n",
    "\n",
    "test['bus_route_id'] = test['bus_route_id'].astype(str)\n",
    "test['station_code'] = test['station_code'].astype(str)\n",
    "test['route_station'] = test['bus_route_id'] + ',' + test['station_code']\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bus_route_id_weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bus_route_id_weekday = bus_route_id + weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bus_route_id_weekday'] = train['bus_route_id'].astype(str) + ',' + train['weekday'].astype(str) \n",
    "test['bus_route_id_weekday'] = test['bus_route_id'].astype(str) + ',' + test['weekday'].astype(str) \n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### station_code_weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "station_code_weekday = station_code + weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['station_code_weekday'] = train['station_code'].astype(str) + ',' + train['weekday'].astype(str)\n",
    "test['station_code_weekday'] = test['station_code'].astype(str) + ',' + test['weekday'].astype(str)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### route_station_weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "route_station_weekday = route_station + weekay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['route_station_weekday'] = train['route_station'].astype(str) + ',' + train['weekday'].astype(str) \n",
    "test['route_station_weekday'] = test['route_station'].astype(str) + ',' + test['weekday'].astype(str)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### on_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bts.csv 데이터에서 geton_time 열에서 시간대만 추출하여 on_time 컬럼을 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts['on_time']  = bts['geton_time'].apply(lambda x : x[:2])\n",
    "\n",
    "bts.iloc[bts.query('on_time == \"06\"').index,13] = '6~7_ride'\n",
    "bts.iloc[bts.query('on_time == \"07\"').index,13] = '7~8_ride'\n",
    "bts.iloc[bts.query('on_time == \"08\"').index,13] = '8~9_ride'\n",
    "bts.iloc[bts.query('on_time == \"09\"').index,13] = '9~10_ride'\n",
    "bts.iloc[bts.query('on_time == \"10\"').index,13] = '10~11_ride'\n",
    "bts.iloc[bts.query('on_time == \"11\"').index,13] = '11~12_ride'\n",
    "\n",
    "bts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 승 하차 시간대 통합 변수 (t ~ t+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t~t+1, t+1~t+2 시간대 승하차인원을 합하여 t~t+2 시간대 승하차인원 변수를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['68a']=train['6~7_ride']+train['7~8_ride'] \n",
    "train['810a']=train['8~9_ride']+train['9~10_ride']\n",
    "train['1012a']=train['10~11_ride']+train['11~12_ride']\n",
    "\n",
    "train['68b']=train['6~7_takeoff']+train['7~8_takeoff'] \n",
    "train['810b']=train['8~9_takeoff']+train['9~10_takeoff']\n",
    "train['1012b']=train['10~11_takeoff']+train['11~12_takeoff']\n",
    "\n",
    "test['68a']=test['6~7_ride']+test['7~8_ride']\n",
    "test['810a']=test['8~9_ride']+test['9~10_ride']\n",
    "test['1012a']=test['10~11_ride']+test['11~12_ride']\n",
    "\n",
    "test['68b']=test['6~7_takeoff']+test['7~8_takeoff']\n",
    "test['810b']=test['8~9_takeoff']+test['9~10_takeoff']\n",
    "test['1012b']=test['10~11_takeoff']+test['11~12_takeoff']\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make features by using target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리가 최종적으로 예측해야할 것은 각 `일자별(date)`, `버스 노선(bus_route_id)` 상의 `정류장(station_name)`의 **`퇴근시간 하차인원(18~20_ride)`**이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bus_route_id, station_name, weekday의 각 **조합**별 퇴근시간 하차인원(18~20_ride)의 여러 통계량을 구한 후 이를 train set, test set에 모두 적용한다.\"\n",
    "\n",
    "\n",
    "- target 변수를 train, test set에 적용할 수 있는 이유는 우리가 예측해야할 id는 date, bus_rout_id, station_name으로 구성되어있기 때문이다. 즉, 각각의 노선, 정류장별로 공통적인 패턴이 존재할 수 있다.\n",
    "\n",
    "\n",
    "- 이 과정에서 NA 값이 생기는 이유는 train set에 없는 bus_route_id, station_name이 존재하기 때문이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_statistic(ID, col1, col2) :\n",
    "    \n",
    "    # mean, sum\n",
    "    rs_mean = train.groupby([ID])['18~20_ride'].agg([(col1, 'mean')]).reset_index()\n",
    "    rs_sum = train.groupby([ID])['18~20_ride'].agg([(col2, 'sum')]).reset_index()\n",
    "    rs_mean_sum = pd.merge(rs_mean, rs_sum, on=ID)\n",
    "\n",
    "    # merge\n",
    "    tr = pd.merge(train, rs_mean_sum, how='left', on=ID)\n",
    "    te = pd.merge(test, rs_mean_sum, how='left', on=ID)\n",
    "\n",
    "    # na -> mean\n",
    "    te[col1] = te[col1].fillna(rs_mean.mean())\n",
    "    te[col1] = te[col1].fillna(rs_sum.mean())\n",
    "    \n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = id_statistic('route_station', '1820_rs_mean', '1820_rs_sum')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = id_statistic('bus_route_id', '1820_r_mean', '1820_r_sum')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = id_statistic('station_code', '1820_s_mean', '1820_s_sum')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = id_statistic('weekday', '1820_w_mean', '1820_w_sum')\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_statistics() :\n",
    "\n",
    "    f = train.groupby(['bus_route_id_weekday'])['18~20_ride'].agg([('mean_bus_weekday_ride','mean')]).reset_index()\n",
    "    tr = pd.merge(train, f, how='left', on='bus_route_id_weekday')\n",
    "    te = pd.merge(test, f, how='left', on='bus_route_id_weekday').fillna(f['mean_bus_weekday_ride'].mean())\n",
    "    \n",
    "    f = train.groupby(['station_code_weekday'])['18~20_ride'].agg([('mean_station_weekday_ride','mean')]).reset_index()\n",
    "    tr = pd.merge(tr, f, how='left', on='station_code_weekday')\n",
    "    te = pd.merge(te, f, how='left', on='station_code_weekday').fillna(f['mean_station_weekday_ride'].mean())\n",
    "    \n",
    "    f = train.groupby(['route_station_weekday'])['18~20_ride'].agg([('mean_route_station_weekday_ride','mean')]).reset_index()\n",
    "    tr = pd.merge(tr, f, how='left', on='route_station_weekday')\n",
    "    te = pd.merge(te, f, how='left', on='route_station_weekday').fillna(f['mean_route_station_weekday_ride'].mean())\n",
    "    \n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = mean_statistics()\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### congestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bus_route_id를 기준으로 18 ~ 20의 혼잡도를 계산한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def congestion() :\n",
    "    df = train.groupby(['bus_route_id'])['18~20_ride'].agg([('passenger', 'sum')])\n",
    "    df = df.sort_values(by='passenger', ascending=False).reset_index()\n",
    "    \n",
    "    def f(x):\n",
    "        if x > 10000:\n",
    "            return 7\n",
    "\n",
    "        elif x > 5000:\n",
    "            return 6\n",
    "\n",
    "        elif x > 2000:\n",
    "            return 5\n",
    "\n",
    "        elif x > 700:\n",
    "            return 4\n",
    "\n",
    "        elif x > 200:\n",
    "            return 3\n",
    "\n",
    "        elif x > 50:\n",
    "            return 2\n",
    "\n",
    "        else:\n",
    "            return 1\n",
    "    \n",
    "    df['congestion']=df['passenger'].apply(f)\n",
    "    df = df[['bus_route_id','congestion']]\n",
    "    \n",
    "    tr = pd.merge(train, df, how='left', on='bus_route_id')\n",
    "    te = pd.merge(test, df, how='left', on='bus_route_id')\n",
    "    \n",
    "    # 결측치는 데이터 프레임 df의 'congestion'의 중간값인 '4'으로 대체\n",
    "    te = te.fillna(4)\n",
    "    \n",
    "    return tr, te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = congestion()\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "location = latitude + longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['location'] = train['latitude'].astype(str) + ',' + train['longitude'].astype(str)\n",
    "test['location'] = test['latitude'].astype(str) + ',' + test['longitude'].astype(str)\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merge key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make cue column\n",
    "train['cue']=0\n",
    "test['cue']=1\n",
    "\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오전 시간의 여러 데이터 활용한 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오전 시간의 탑승 및 하차 데이터를 활용하여 요약통계량을 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morning() :\n",
    "    \n",
    "    # merge\n",
    "    data = pd.concat([train, test])\n",
    "    \n",
    "    a = data.groupby(['route_station'])['1012a'].agg({'sum', 'mean'}).reset_index()\n",
    "    a.columns = ['route_station', '1012a_sum','1012a_mean']\n",
    "\n",
    "    b = data.groupby(['route_station'])['1012b'].agg({'sum', 'mean'}).reset_index()\n",
    "    b.columns = ['route_station', '1012b_sum','1012b_mean']\n",
    "    b = b[['1012b_sum','1012b_mean']]\n",
    "\n",
    "    c = data.groupby(['route_station'])['10~11_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    c.columns = ['route_station', '10~11_ride_sum','10~11_ride_mean']\n",
    "    c = c[['10~11_ride_sum','10~11_ride_mean']]\n",
    "\n",
    "    d = data.groupby(['route_station'])['10~11_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    d.columns = ['route_station', '10~11_takeoff_sum','10~11_takeoff_mean']\n",
    "    d = d[['10~11_takeoff_sum','10~11_takeoff_mean']]\n",
    "\n",
    "    e = data.groupby(['route_station'])['11~12_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    e.columns = ['route_station', '11~12_ride_sum','11~12_ride_mean']\n",
    "    e = e[['11~12_ride_sum','11~12_ride_mean']]\n",
    "\n",
    "    f = data.groupby(['route_station'])['11~12_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    f.columns = ['route_station', '11~12_takeoff_sum','11~12_takeoff_mean']\n",
    "    f = f[['11~12_takeoff_sum','11~12_takeoff_mean']]\n",
    "\n",
    "    g = data.groupby(['route_station'])['1820_r_mean'].agg({'sum', 'mean'}).reset_index()\n",
    "    g.columns = ['route_station', '1820_r_mean_sum','1820_r_mean_mean']\n",
    "    g = g[['1820_r_mean_sum','1820_r_mean_mean']]\n",
    "\n",
    "    h = data.groupby(['route_station'])['1820_r_sum'].agg({'sum', 'mean'}).reset_index()\n",
    "    h.columns = ['route_station', '1820_r_sum_sum','1820_r_sum_mean']\n",
    "    h = h[['1820_r_sum_sum','1820_r_sum_mean']]\n",
    "\n",
    "    i = data.groupby(['route_station'])['1820_rs_mean'].agg({'sum', 'mean'}).reset_index()\n",
    "    i.columns = ['route_station', '1820_rs_mean_sum','1820_rs_mean_mean']\n",
    "    i = i[['1820_rs_mean_sum','1820_rs_mean_mean']]\n",
    "\n",
    "    j = data.groupby(['route_station'])['1820_rs_sum'].agg({'sum', 'mean'}).reset_index()\n",
    "    j.columns = ['route_station', '1820_rs_sum_sum','1820_rs_sum_mean']\n",
    "    j = j[['1820_rs_sum_sum','1820_rs_sum_mean']]\n",
    "\n",
    "    k = data.groupby(['route_station'])['1820_s_mean'].agg({'sum', 'mean'}).reset_index()\n",
    "    k.columns = ['route_station', '1820_s_mean_sum','1820_s_mean_mean']\n",
    "    k = k[['1820_s_mean_sum','1820_s_mean_mean']]\n",
    "\n",
    "    l = data.groupby(['route_station'])['1820_s_sum'].agg({'sum', 'mean'}).reset_index()\n",
    "    l.columns = ['route_station', '1820_s_sum_sum','1820_s_sum_mean']\n",
    "    l = l[['1820_s_sum_sum','1820_s_sum_mean']]\n",
    "\n",
    "    m = data.groupby(['route_station'])['1820_w_mean'].agg({'sum', 'mean'}).reset_index()\n",
    "    m.columns = ['route_station', '1820_w_mean_sum','1820_w_mean_mean']\n",
    "    m = m[['1820_w_mean_sum','1820_w_mean_mean']]\n",
    "\n",
    "    n = data.groupby(['route_station'])['1820_w_sum'].agg({'sum', 'mean'}).reset_index()\n",
    "    n.columns = ['route_station', '1820_w_sum_sum','1820_w_sum_mean']\n",
    "    n = n[['1820_w_sum_sum','1820_w_sum_mean']]\n",
    "\n",
    "    o = data.groupby(['route_station'])['68a'].agg({'sum', 'mean'}).reset_index()\n",
    "    o.columns = ['route_station', '68a_sum','68a_mean']\n",
    "    o = o[['68a_sum','68a_mean']]\n",
    "\n",
    "    p = data.groupby(['route_station'])['68b'].agg({'sum', 'mean'}).reset_index()\n",
    "    p.columns = ['route_station', '68b_sum','68b_mean']\n",
    "    p = p[['68b_sum','68b_mean']]\n",
    "\n",
    "    q = data.groupby(['route_station'])['6~7_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    q.columns = ['route_station', '6~7_ride_sum','6~7_ride_mean']\n",
    "    q = q[['6~7_ride_sum','6~7_ride_mean']]\n",
    "\n",
    "    r = data.groupby(['route_station'])['6~7_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    r.columns = ['route_station', '6~7_takeoff_sum','6~7_takeoff_mean']\n",
    "    r = r[['6~7_takeoff_sum','6~7_takeoff_mean']]\n",
    "\n",
    "    s = data.groupby(['route_station'])['7~8_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    s.columns = ['route_station', '7~8_ride_sum','7~8_ride_mean']\n",
    "    s = s[['7~8_ride_sum','7~8_ride_mean']]\n",
    "\n",
    "    t = data.groupby(['route_station'])['7~8_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    t.columns = ['route_station', '7~8_takeoff_sum','7~8_takeoff_mean']\n",
    "    t = t[['7~8_takeoff_sum','7~8_takeoff_mean']]\n",
    "\n",
    "    u = data.groupby(['route_station'])['810a'].agg({'sum', 'mean'}).reset_index()\n",
    "    u.columns = ['route_station', '810a_sum','810a_mean']\n",
    "    u = u[['810a_sum','810a_mean']]\n",
    "\n",
    "    v = data.groupby(['route_station'])['810b'].agg({'sum', 'mean'}).reset_index()\n",
    "    v.columns = ['route_station', '810b_sum','810b_mean']\n",
    "    v = v[['810b_sum','810b_mean']]\n",
    "\n",
    "    w = data.groupby(['route_station'])['8~9_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    w.columns = ['route_station', '8~9_ride_sum','8~9_ride_mean']\n",
    "    w = w[['8~9_ride_sum','8~9_ride_mean']]\n",
    "\n",
    "    x = data.groupby(['route_station'])['8~9_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    x.columns = ['route_station', '8~9_takeoff_sum','8~9_takeoff_mean']\n",
    "    x = x[['8~9_takeoff_sum','8~9_takeoff_mean']]\n",
    "\n",
    "    y = data.groupby(['route_station'])['9~10_ride'].agg({'sum', 'mean'}).reset_index()\n",
    "    y.columns = ['route_station', '9~10_ride_sum','9~10_ride_mean']\n",
    "    y = y[['9~10_ride_sum','9~10_ride_mean']]\n",
    "\n",
    "    z = data.groupby(['route_station'])['9~10_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
    "    z.columns = ['route_station', '9~10_takeoff_sum','9~10_takeoff_mean']\n",
    "    z = z[['9~10_takeoff_sum','9~10_takeoff_mean']]\n",
    "    \n",
    "    df = pd.concat([a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z],axis=1)\n",
    "    df = pd.merge(data, df, how='left', on='route_station')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = morning()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 배차 간격"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배차 간격 변수를 만들 때는 많은 시간이 소요됩니다. 따라서 위의 과정의 결과를 데이터프레임으로 구성해놓았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['bus_route_id'] = train['bus_route_id'].astype(np.int64)\n",
    "test['bus_route_id'] = test['bus_route_id'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bts['geton_time2'] = pd.to_datetime(bts['geton_time'])\n",
    "\n",
    "f = bts.groupby(['geton_date','geton_time2','geton_station_code','bus_route_id'])['user_count'].\\\n",
    "agg([('탑승객_수','sum')]).reset_index().\\\n",
    "sort_values(by=['geton_date','geton_station_code','bus_route_id','geton_time2'], ascending=True).reset_index()\n",
    "\n",
    "f['index'] = list(range(0,len(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = []\n",
    "\n",
    "for i in range(0,len(f)-1):\n",
    "\n",
    "    if ((f.iloc[i].geton_date == f.iloc[i+1].geton_date) &\\\n",
    "        (f.iloc[i].geton_station_code == f.iloc[i+1].geton_station_code) &\\\n",
    "        (f.iloc[i].bus_route_id == f.iloc[i+1].bus_route_id)):\n",
    "\n",
    "        time.append(f.iloc[i+1].geton_time2 - f.iloc[i].geton_time2)\n",
    "\n",
    "    else:\n",
    "        time.append(0)\n",
    "\n",
    "time.insert(0, '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sec(time_str):\n",
    "\n",
    "    h, m, s = time_str.split(':')\n",
    "\n",
    "    return int(h) * 3600 + int(m) * 60 + int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bus_interval() :\n",
    "\n",
    "    f['time'] = time\n",
    "    f['time2'] = f['time'].astype(str).str[7:]\n",
    "\n",
    "\n",
    "    interval = f.copy()\n",
    "    interval['time2'] = interval['time2'].astype(str).replace('','00:00:00')\n",
    "    interval['bus_route_id'] = interval['bus_route_id'].astype(object)\n",
    "\n",
    "    time4 = []\n",
    "\n",
    "    for i in interval['time2'] :\n",
    "\n",
    "        time4.append(get_sec(i))\n",
    "\n",
    "    interval['time4'] = time4\n",
    "    interval['time4'] = (interval['time4'] / 60).astype(int)\n",
    "\n",
    "    interval = interval[interval['time4'] > 3] # 간격이 3분보다 작은 것 제외 \n",
    "    interval = interval[interval['time4'] < 180] # 간격이 3시간보다 큰 것 제외\n",
    "\n",
    "    interval = interval.groupby('bus_route_id')['time4'].agg([('bus_interval', 'mean')]).reset_index()\n",
    "    interval['bus_interval'] = interval['bus_interval'].astype(int)\n",
    "\n",
    "    # 나중에 시간을 절약하기 위해 csv 파일로 저장\n",
    "    interval.to_csv('bus_interval_final.csv', index = False)\n",
    "\n",
    "    print('success.. !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_interval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 과정은 상당히 오래걸리는 관계로 따로 데이터셋을 만들어서 구성해놓았습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_interval = pd.read_csv(\"bus_interval_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bus_route_id'] = data['bus_route_id'].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, bus_interval, how = 'left', on = 'bus_route_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'bus_interval'컬럼에서 na값을 가지는 행들을 분석해본 결과, 대부분 18~20시의 탑승 인원이 거의 없는 bus_route_id 와 station_code 였다. 따라서 탑승 인원이 별로 없을 것이라고 예상되는 버스는 배차 간격이 길 것이라고 판단하여 na값을 '9999' 로 채워주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bus_interval'] = data['bus_interval'].fillna(9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label encoding feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bus_route_id, station_name, route_station_weekday(bus_route_id + weekday의 조합), route_station(bus_route_id + station_code 의 조합) 총 4개를 라벨인코딩 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df_encode = data[['bus_route_id','station_code', 'route_station_weekday', 'route_station']]\n",
    "df_encoded = df_encode.apply(labelencoder.fit_transform)\n",
    "\n",
    "data['bus_route_id2']=df_encoded['bus_route_id']\n",
    "data['station_code2']=df_encoded['station_code']\n",
    "data['route_station_weekday2']=df_encoded['route_station_weekday']\n",
    "data['route_station2']=df_encoded['route_station']\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "날씨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather() :\n",
    "\n",
    "    weather_data = pd.read_csv('weather.csv', encoding = 'utf-8')\n",
    "    weather_data['id'] = range(0,46)\n",
    "\n",
    "    a = pd.DataFrame(data.date.unique(), columns=['date']) ; a['id'] = range(0,46)\n",
    "    weather_data = pd.merge(a, weather_data)\n",
    "    weather_data = weather_data[['date','현재일기_10','체감온도_10','일강수_10']]\n",
    "    weather_data = weather_data.replace(' ', 0)\n",
    "    df = pd.merge(data, weather_data, on='date')\n",
    "    # label_encoder\n",
    "    labelencoder = LabelEncoder()\n",
    "    df_encode = df[['현재일기_10']]\n",
    "    df_encoded = df_encode.apply(labelencoder.fit_transform)\n",
    "    df['현재일기_10']=df_encoded['현재일기_10']\n",
    "    # object->float 변수변환\n",
    "    df['현재일기_10'] = df['현재일기_10'].astype(float)\n",
    "    df['체감온도_10'] = df['체감온도_10'].astype(float)\n",
    "    df['일강수_10'] = df['일강수_10'].astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = weather()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weekday (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['weekday'] = data['date'].dt.weekday\n",
    "data = pd.get_dummies(data,columns=['weekday'])\n",
    "data['weekday'] = data['date'].dt.weekday\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### in - out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['in_out'].value_counts()\n",
    "data['in_out'] = data['in_out'].map({'시내':0,'시외':1})\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 좌표데이터를 이용 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "좌표데이터를 이용한 변수를 만들 때는 많은 시간이 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_jejusi = (33.500770, 126.522761) #제주시의 위도 경도\n",
    "data['dis_jejusi'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejusi).km for i in range(len(data))]\n",
    "\n",
    "coords_jejusicheong1 = (33.49892, 126.53035) #제주시청(광양방면)의 위도 경도\n",
    "coords_jejuairport = (33.50661, 126.49345) #제주국제공항(구제주방면)의 위도 경도\n",
    "coords_hallahosp = (33.48963, 126.486) #한라병원의 위도 경도\n",
    "coords_rotary = (33.49143, 126.49678) # 제주도청신제주로터리의 위도 경도\n",
    "coords_jejucenterhigh = (33.48902, 126.5392) #제주중앙여자고등학교의 위도 경도\n",
    "coords_jejumarket = (33.51315, 126.52706) #동문시장의 위도 경도\n",
    "coords_jejusclass = (33.47626, 126.48141) #제주고등학교/중흥S클래스의 위도 경도\n",
    "coords_centerroad = (33.51073, 126.5239) #중앙로(국민은행)의 위도 경도\n",
    "coords_fiveway = (33.48667, 126.48092) # 노형오거리의 위도 경도\n",
    "coords_law = (33.49363, 126.53476) # 제주지방법원(광양방면)의 위도 경도\n",
    "\n",
    "data['dis_jejusicheong1'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejusicheong1).km for i in range(len(data))]\n",
    "data['dis_jejuairport'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejuairport).km for i in range(len(data))]\n",
    "data['dis_hallahosp'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_hallahosp).km for i in range(len(data))]\n",
    "data['dis_rotary'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_rotary).km for i in range(len(data))]\n",
    "data['dis_jejucenterhigh'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejucenterhigh).km for i in range(len(data))]\n",
    "data['dis_jejumarket'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejumarket).km for i in range(len(data))]\n",
    "data['dis_jejusclass'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejusclass).km for i in range(len(data))]\n",
    "data['dis_centerroad'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_centerroad).km for i in range(len(data))]\n",
    "data['dis_fiveway'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_fiveway).km for i in range(len(data))]\n",
    "data['dis_law'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_law).km for i in range(len(data))]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 출근 시간의 총 승객 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ride_sum'] = data['6~7_ride'] + data['7~8_ride'] + data['8~9_ride'] + data['9~10_ride'] + data['10~11_ride'] + data['11~12_ride'] \n",
    "data['takeoff_sum'] = data['6~7_takeoff'] + data['7~8_takeoff'] + data['8~9_takeoff'] + data['9~10_takeoff'] + data['10~11_takeoff'] + data['11~12_takeoff'] \n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 날짜 및 시간대 별 총 승객수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = data.groupby('date')['6~7_ride'].agg([('6~7_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "f = data.groupby('date')['7~8_ride'].agg([('7~8_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "f = data.groupby('date')['8~9_ride'].agg([('8~9_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "f = data.groupby('date')['9~10_ride'].agg([('9~10_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "f = data.groupby('date')['10~11_ride'].agg([('10~11_all_ride_number', 'sum')]).reset_index()\n",
    "data = pd.merge(data, f, how='left')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주말, 주중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(x):\n",
    "    if x ==5:\n",
    "        return 1\n",
    "    elif x==6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['weekend'] = data['weekday'].apply(h)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 연휴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x):\n",
    "    if x in ['2019-09-12','2019-09-13','2019-09-14','2019-10-03','2019-10-09']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['holiday'] = data['date'].apply(g) \n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 요일 별 평균 승객 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def week_mean() :\n",
    "\n",
    "    df = data.reset_index(drop=True)\n",
    "    df.groupby('weekday')['18~20_ride'].mean()\n",
    "    df['weekdaymean']= 1\n",
    "\n",
    "    index0 = df.query('weekday==0').index\n",
    "    index1 = df.query('weekday==1').index\n",
    "    index2 = df.query('weekday==2').index\n",
    "    index3 = df.query('weekday==3').index\n",
    "    index4 = df.query('weekday==4').index\n",
    "    index5 = df.query('weekday==5').index\n",
    "    index6 = df.query('weekday==6').index\n",
    "\n",
    "    df.iloc[index0,-1] = 1.343710\n",
    "    df.iloc[index1,-1] = 1.375319\n",
    "    df.iloc[index2,-1] = 1.430856\n",
    "    df.iloc[index3,-1] = 1.256710\n",
    "    df.iloc[index4,-1] = 1.067439\n",
    "    df.iloc[index5,-1] = 1.062123\n",
    "    df.iloc[index6,-1] = 1.034282\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = week_mean()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시내 및 시외버스 별 평균 탑승 승객"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['in_out_mean'] = 1\n",
    "inindex = data.query('in_out == \"시내\"').index\n",
    "outindex = data.query('in_out == \"시외\"').index\n",
    "\n",
    "data.iloc[inindex,-1] = 1.228499\n",
    "data.iloc[outindex,-1] = 2.044345\n",
    "data['congestion'] = data['congestion'].astype('int64')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 카테고리별 승객 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_people() :\n",
    "    bts['bus_route_id'] = bts['bus_route_id'].astype(str)\n",
    "\n",
    "    f = bts.groupby(['bus_route_id','user_category'])['user_count'].agg([('승객수', 'sum')]).reset_index()\n",
    "\n",
    "    g = pd.pivot_table(f, values='승객수', index='bus_route_id', columns='user_category',fill_value=0).reset_index()\n",
    "    g.columns = ['bus_route_id', 'adult','kids','teen','elder','jang','jang2','ugong','ugong2']\n",
    "    g = g[['bus_route_id', 'adult','kids','teen','elder']]\n",
    "\n",
    "    # merge\n",
    "    df = pd.merge(data, g, how='left', on='bus_route_id')\n",
    "\n",
    "    # na preprocessing -> mean value\n",
    "    df['adult'] = df['adult'].fillna(2363.077778)\n",
    "    df['kids'] = df['kids'].fillna(60.426984)\n",
    "    df['teen'] = df['teen'].fillna(448.277778)\n",
    "    df['elder'] = df['elder'].fillna(751.309524)\n",
    "                 \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bus_route_id'] = data['bus_route_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = category_people()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category별 승객의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_people_ratio() :\n",
    "    \n",
    "    a = bts.groupby('bus_route_id')['user_count'].agg([('전체', 'sum')]).reset_index()\n",
    "    b = bts.groupby(['bus_route_id','user_category'])['user_count'].agg([('승객수', 'sum')]).reset_index()\n",
    "\n",
    "    c = pd.merge(b, a, on='bus_route_id')\n",
    "    c['비율'] = c['승객수']/c['전체']\n",
    "    c = pd.pivot_table(c, values='비율', index='bus_route_id', columns='user_category',fill_value=0).reset_index()\n",
    "    c.columns = ['bus_route_id', 'adult_prop','kids_prop','teen_prop','elder_prop','jang_prop','jang2_prop','ugong_prop','ugong2_prop']\n",
    "    f = c[['bus_route_id', 'adult_prop','kids_prop','teen_prop','elder_prop']]\n",
    "\n",
    "    df = pd.merge(data, f, how='left', on='bus_route_id')\n",
    "\n",
    "    # na preprocessing -> mean value\n",
    "    df['adult_prop'] = df['adult_prop'].fillna(0.549702)\n",
    "    df['kids_prop'] = df['kids_prop'].fillna(60.426984)\n",
    "    df['teen_prop'] = df['teen_prop'].fillna(0.019902)\n",
    "    df['elder_prop'] = df['elder_prop'].fillna(0.235848)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = category_people_ratio()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 동,읍,면별 직업군별 비율, 평균소득액, 평균소비액"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jeju_finantial_life_data (외부데이터) 사용하여 피쳐 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test 데이터의 'latitude', 'longitude'열, jeju_financial_life_data의 'X_AXIS', 'Y_AXIS'열을 지오코딩 프로그램을 사용하여 주소로 변환하였다. 변환한 주소를 전처리 하여 동 기준으로 두 데이터를 합쳐주었다. 그 뒤 파생변수를 생성하였다.\n",
    "data_address.csv는 data의 주소가, life_address.csv는 jeju_finantial_life_data의 주소가 담겨있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jeoju_love() :\n",
    "    \n",
    "    loc_data = pd.read_csv(\"data_address.csv\", encoding='cp949')\n",
    "    loc_life = pd.read_csv(\"life_address.csv\", encoding='cp949')\n",
    "    \n",
    "    loc_data = loc_data[['location','dong', 'si']]\n",
    "    loc_life = loc_life[['location','dong', 'si']]\n",
    "\n",
    "    df = pd.merge(data, loc_data, how='left', on='location')\n",
    "    \n",
    "    jeju_life = pd.read_csv(\"jeju_financial_life_data.csv\")\n",
    "    jeju_life['location'] = jeju_life['x_axis'].astype(str).str[:10] + ',' + jeju_life['y_axis'].astype(str).str[:10]\n",
    "    jeju_life2 = pd.merge(jeju_life, loc_life, how='left', on='location')\n",
    "\n",
    "    dong_f1 = jeju_life2.groupby(['dong'])[['job_majorc', 'job_smallc', 'job_public', 'job_profession', 'job_self','vehicle_own_rat', 'avg_income', 'med_income', 'avg_spend']].mean().reset_index()\n",
    "    dong_f1.columns=['dong','mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self','mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend']\n",
    "\n",
    "    dong_f2 = jeju_life2.groupby(['dong'])[['job_majorc', 'job_smallc', 'job_public', 'job_profession', 'job_self','vehicle_own_rat', 'avg_income', 'med_income', 'avg_spend']].sum().reset_index()\n",
    "    dong_f2.columns=['dong','sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self','sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income', 'sum_avg_spend']\n",
    "\n",
    "    dong_f3 = (jeju_life2.groupby(['dong'])['job_majorc', 'job_smallc', 'job_public', 'job_profession', 'job_self','vehicle_own_rat', 'avg_income', 'med_income', 'avg_spend'].sum()/jeju_life2.groupby(['dong'])['job_majorc', 'job_smallc', 'job_public', 'job_profession', 'job_self','vehicle_own_rat', 'avg_income', 'med_income', 'avg_spend'].sum().sum()).reset_index()\n",
    "    dong_f3.columns = ['dong','rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self','rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income', 'rate_avg_spend']\n",
    "\n",
    "    m_1 = pd.merge(dong_f1, dong_f2, how='left', on='dong')\n",
    "    m_2 = pd.merge(m_1, dong_f3, how='left', on='dong')\n",
    "    df = pd.merge(df, m_2, how='left', on='dong')\n",
    "\n",
    "    #  # na preprocessing -> mean value\n",
    "    df['mean_job_majorc'] = df['mean_job_majorc'].fillna(0.024219)\n",
    "    df['mean_job_smallc'] = df['mean_job_smallc'].fillna(0.145757)\n",
    "    df['mean_job_public'] = df['mean_job_public'].fillna(0.032768)\n",
    "    df['mean_job_profession'] = df['mean_job_profession'].fillna(0.014855)\n",
    "    df['mean_job_self'] = df['mean_job_self'].fillna(0.222090)\n",
    "    df['mean_vehicle_own_rat'] = df['mean_vehicle_own_rat'].fillna(0.041161)\n",
    "    df['mean_avg_income'] = df['mean_avg_income'].fillna(34221420)\n",
    "    df['mean_med_income'] = df['mean_med_income'].fillna(30645290)\n",
    "    df['mean_avg_spend'] = df['mean_avg_spend'].fillna(4224923)\n",
    "\n",
    "    df['sum_job_majorc'] = df['sum_job_majorc'].fillna(3.717861e+00)\n",
    "    df['sum_job_smallc'] = df['sum_job_smallc'].fillna(2.078142e+01)\n",
    "    df['sum_job_public'] = df['sum_job_public'].fillna(4.747755e+00)\n",
    "    df['sum_job_profession'] = df['sum_job_profession'].fillna(2.169554e+00)\n",
    "    df['sum_job_self'] = df['sum_job_self'].fillna(3.044199e+01)\n",
    "    df['sum_vehicle_own_rat'] = df['sum_vehicle_own_rat'].fillna(5.609080e+00)\n",
    "    df['sum_avg_income'] = df['sum_avg_income'].fillna(4.998226e+09)\n",
    "    df['sum_med_income'] = df['sum_med_income'].fillna(4.455924e+09)\n",
    "    df['sum_avg_spend'] = df['sum_avg_spend'].fillna(6.147678e+08)\n",
    "\n",
    "    df['rate_job_majorc'] = df['rate_job_majorc'].fillna(1.388889e-02)\n",
    "    df['rate_job_smallc'] = df['rate_job_smallc'].fillna(1.388889e-02)\n",
    "    df['rate_job_public'] = df['rate_job_public'].fillna(1.388889e-02)\n",
    "    df['rate_job_profession'] = df['rate_job_profession'].fillna(1.388889e-02)\n",
    "    df['rate_job_self'] = df['rate_job_self'].fillna(1.388889e-02)\n",
    "    df['rate_vehicle_own_rat'] = df['rate_vehicle_own_rat'].fillna(1.388889e-02)\n",
    "    df['rate_avg_income'] = df['rate_avg_income'].fillna(1.388889e-02)\n",
    "    df['rate_med_income'] = df['rate_med_income'].fillna(1.388889e-02)\n",
    "    df['rate_avg_spend'] = df['rate_avg_spend'].fillna(1.388889e-02)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = jeoju_love()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수요가 많을 것으로 예상되는 정류장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data[data['station_name'].str.contains('고등학교')]\n",
    "highschool = list(g['station_name'].unique())\n",
    "\n",
    "g = data[data['station_name'].str.contains('대학교')]\n",
    "university = list(g['station_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x in highschool:\n",
    "        return 1\n",
    "    elif x in university:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['school'] = data['station_name'].apply(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = data[data['station_name'].str.contains('환승')]\n",
    "transfer = list(g['station_name'].unique())\n",
    "\n",
    "g = data[data['station_name'].str.contains('공항')]\n",
    "airport = list(g['station_name'].unique())\n",
    "\n",
    "g = data[data['station_name'].str.contains('터미널')]\n",
    "terminal = list(g['station_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x in transfer:\n",
    "        return 1\n",
    "    elif x in airport:\n",
    "        return 1\n",
    "    elif x in terminal:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['transfer'] = data['station_name'].apply(f) \n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 동 - 라벨인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "df_encode = data[['dong']]\n",
    "df_encoded = df_encode.apply(labelencoder.fit_transform)\n",
    "\n",
    "data['dong2']=df_encoded['dong']\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 측정소와 정류장 사이 거리 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist() :\n",
    "    jeju=(33.51411, 126.52969) # 제주 측정소 근처\n",
    "    gosan=(33.29382, 126.16283) #고산 측정소 근처\n",
    "    seongsan=(33.38677, 126.8802) #성산 측정소 근처\n",
    "    po=(33.24616, 126.5653) #서귀포 측정소 근처\n",
    "\n",
    "    t1 = [geopy.distance.vincenty( (i,j), jeju).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t2 = [geopy.distance.vincenty( (i,j), gosan).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t3 = [geopy.distance.vincenty( (i,j), seongsan).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "    t4 = [geopy.distance.vincenty( (i,j), po).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
    "\n",
    "    data['dis_jeju'] = t1\n",
    "    data['dis_gosan']=t2\n",
    "    data['dis_seongsan']=t3\n",
    "    data['dis_po']=t4\n",
    "\n",
    "    total = pd.DataFrame(list(zip( t1,t2,t3,t4)),columns=['jeju','gosan','seongsan','po'] )\n",
    "    data['dist_name'] = total.apply(lambda x: x.argmin(), axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dist()\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 날씨 관련 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중급자코드를 참고하면 rain3.csv를 만들 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain3 = pd.read_csv(\"rain3.csv\")\n",
    "\n",
    "# train, test의 변수명과 통일시키고, NaN의 값은 0.0000으로 변경\n",
    "rain3 = rain3.rename(columns={\"일시\":\"date\",\"지점\":\"dist_name\"})\n",
    "rain3 = rain3.fillna(0.00000)\n",
    "rain3['date'] = pd.to_datetime(rain3['date'])\n",
    "\n",
    "rain3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data, rain3, how='left',on=['dist_name','date'])\n",
    "data = pd.get_dummies(data,columns=['dist_name'])\n",
    "data = pd.get_dummies(data,columns=['si'])\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rainy_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "비 오는날=1, 비 안오는 날=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['rainy_day'] = data['강수량(mm)'].apply(f)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 승 하차 시간대 통합 변수 (t ~ t+3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t~t+1, t+1~t+2, t+2~t+3 시간대 승하차인원을 합하여 t~t+3 시간대 승하차인원 변수를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['69a'] = data['6~7_ride']+data['7~8_ride']+data['8~9_ride']\n",
    "data['912a']=data['9~10_ride']+data['10~11_ride']+data['11~12_ride']\n",
    "\n",
    "data['69b'] = data['6~7_takeoff']+data['7~8_takeoff']+data['8~9_takeoff']\n",
    "data['912b'] = data['9~10_takeoff']+data['10~11_takeoff']+data['11~12_takeoff']\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train, test 데이터를 만들어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.query('cue==\"0\"').reset_index()\n",
    "test_data = data.query('cue==\"1\"').reset_index()\n",
    "\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약통계량을 통한 변수를 만드는 과정에서 NA가 발생한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target variable을 분리한 후 데이터를 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data[['18~20_ride']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape, test_data.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('X_train.csv', index = False, encoding = 'utf-8')\n",
    "test_data.to_csv('X_test.csv', index = False, encoding = 'utf-8')\n",
    "y_train.to_csv('y_train.csv', index = False, encoding = 'utf-8')\n",
    "\n",
    "print('save ..!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('X_train.csv', encoding = 'utf-8')\n",
    "test_data = pd.read_csv('X_test.csv', encoding = 'utf-8')\n",
    "y_train = pd.read_csv('y_train.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var_0=['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
    "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
    "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
    "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
    "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
    "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
    "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
    "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
    "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', 'elder_prop',\n",
    "           'mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self',\n",
    "           'mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend', \n",
    "           'rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self', \n",
    "           'rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income','rate_avg_spend',\n",
    "           'sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self', \n",
    "           'sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income','sum_avg_spend',\n",
    "           '68a', '810a', '1012a', '68b', '810b', '1012b','69a','912a','69b','912b',\n",
    "           'dis_jeju', 'dis_gosan', 'dis_seongsan', 'dis_po', '기온(°C)', '강수량(mm)',\n",
    "           'dist_name_gosan', 'dist_name_jeju', 'dist_name_po', 'dist_name_seongsan', 'si_서귀포시', 'si_제주시',\n",
    "           'school', 'transfer', 'dong2', 'rainy_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var_1=['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
    "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
    "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
    "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
    "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
    "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
    "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
    "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
    "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', 'elder_prop',\n",
    "           'mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self',\n",
    "           'mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend', \n",
    "           'rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self', \n",
    "           'rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income','rate_avg_spend',\n",
    "           'sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self', \n",
    "           'sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income','sum_avg_spend',\n",
    "           '68a', '810a', '1012a', '68b', '810b', '1012b','69a','912a','69b','912b',\n",
    "           'dis_jeju', 'dis_gosan', 'dis_seongsan', 'dis_po', '기온(°C)', '강수량(mm)',\n",
    "           'dist_name_gosan', 'dist_name_jeju', 'dist_name_po', 'dist_name_seongsan', 'si_서귀포시', 'si_제주시',\n",
    "           'school', 'transfer', 'dong2', 'rainy_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var_2=['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
    "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
    "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
    "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
    "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
    "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
    "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
    "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
    "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', 'elder_prop',\n",
    "           'mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self',\n",
    "           'mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend', \n",
    "           'rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self', \n",
    "           'rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income','rate_avg_spend',\n",
    "           'sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self', \n",
    "           'sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income','sum_avg_spend',\n",
    "           '68a', '810a', '1012a', '68b', '810b', '1012b','69a','912a','69b','912b',\n",
    "           'dis_jeju', 'dis_gosan', 'dis_seongsan', 'dis_po', '기온(°C)', '강수량(mm)',\n",
    "           'dist_name_gosan', 'dist_name_jeju', 'dist_name_po', 'dist_name_seongsan', 'si_서귀포시', 'si_제주시',\n",
    "           'school', 'transfer', 'dong2', 'rainy_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var_3 =['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
    "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
    "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
    "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
    "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
    "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
    "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
    "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
    "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', \n",
    "           'elder_prop', 'mean_job_majorc', 'mean_job_smallc',\n",
    "           'mean_job_public', 'mean_job_profession', 'mean_job_self','mean_vehicle_own_rat',\n",
    "          '68a', '810a', '1012a', '68b', '810b', '1012b',\n",
    "          'dis_jeju', 'dis_gosan','dis_seongsan', 'dis_po','기온(°C)', '강수량(mm)', \n",
    "           'dist_name_gosan', 'dist_name_jeju','dist_name_po', 'dist_name_seongsan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_var_4 = ['sum_avg_spend', '68a', '810a', 'si_제주시',  'dong2' , 'bus_interval', 'dis_jejuairport', 'ride_sum',\n",
    "             'takeoff_sum', '1820_rs_mean', '1820_rs_sum','1820_r_mean','1820_r_sum', '1820_s_mean',\n",
    "             '1820_s_sum','congestion', 'bus_route_id2', '6~7_all_ride_number', '7~8_all_ride_number',\n",
    "             '8~9_all_ride_number', '1012a_mean', '1012b_sum','10~11_ride_sum', '10~11_takeoff_sum', '11~12_ride_sum',\n",
    "             '11~12_takeoff_sum', '1820_r_mean_sum', '1820_r_mean_mean',\n",
    "             '1820_r_sum_sum', '1820_r_sum_mean', '1820_rs_mean_sum',\n",
    "             '1820_s_mean_sum', '1820_s_mean_mean', '1820_s_sum_sum',\n",
    "             '1820_s_sum_mean', '1820_w_mean_sum', '1820_w_mean_mean',\n",
    "             '1820_w_sum_mean', '68a_sum', '68a_mean', '68b_sum', 'in_out', 'latitude', 'longitude',\n",
    "             '6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride', '6~7_takeoff', '7~8_takeoff',\n",
    "             '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
    "             'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4',\n",
    "             'weekday_5', 'weekday_6', 'dis_jejusi', '68b_mean', '6~7_ride_sum',\n",
    "             '6~7_ride_mean', '6~7_takeoff_sum', '6~7_takeoff_mean', '7~8_ride_sum',\n",
    "             '7~8_ride_mean', '7~8_takeoff_sum', '7~8_takeoff_mean', '810a_sum',\n",
    "             '810b_sum', '8~9_ride_sum', '8~9_takeoff_sum', '8~9_takeoff_mean',\n",
    "             '9~10_ride_sum', '9~10_takeoff_sum', 'route_station_weekday2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = lgb.LGBMRegressor(num_iterations = 1000, \n",
    "                                learning_rate = 0.05,\n",
    "                                boosting = 'dart',\n",
    "                         Metric = 'regression_l2', n_jobs=-1)\n",
    "\n",
    "X = train_data[input_var_0]\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns=range(len(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm.predict(test_data[input_var_0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_sample.csv')\n",
    "sub['18~20_ride'] = y_pred\n",
    "sub.to_csv('lgbm0=229.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_features=5,\n",
    "                           min_samples_leaf=1,\n",
    "                           min_samples_split=2,\n",
    "                           n_estimators=300,\n",
    "                           random_state=1217)\n",
    "\n",
    "X = train_data[input_var_1]\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(train_data[input_var_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(test_data[input_var_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_sample.csv')\n",
    "sub['18~20_ride'] = y_pred\n",
    "sub.to_csv('rf1=234.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(random_state=1217,\n",
    "                           max_features= 3,\n",
    "                           min_samples_leaf= 2,\n",
    "                           min_samples_split=2,\n",
    "                           n_estimators=500)\n",
    "\n",
    "X = train_data[input_var_2]\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(train_data[input_var_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(test_data[input_var_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_sample.csv')\n",
    "sub['18~20_ride'] = y_pred\n",
    "sub.to_csv('rf2=238.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_features=3,\n",
    "                           min_samples_leaf=2,\n",
    "                           min_samples_split=2,\n",
    "                           n_estimators=500,\n",
    "                           random_state=1217)\n",
    "\n",
    "X = train_data[input_var_3]\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(train_data[input_var_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(test_data[input_var_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_sample.csv')\n",
    "sub['18~20_ride'] = y_pred\n",
    "sub.to_csv('rf3=236.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_features=3,\n",
    "                           min_samples_leaf=2,\n",
    "                           min_samples_split=2,\n",
    "                           n_estimators=500,\n",
    "                           random_state=1217)\n",
    "\n",
    "X = train_data[input_var_4]\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(train_data[input_var_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(test_data[input_var_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_sample.csv')\n",
    "sub['18~20_ride'] = y_pred\n",
    "sub.to_csv('rf4=231.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 변수별 성능 및 상관관계 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "\n",
    "file_list = ['lgbm0=229.csv', 'rf1=234.csv', 'rf2=238.csv', 'rf3=236.csv', 'rf4=231.csv']\n",
    "\n",
    "for item in file_list :\n",
    "    if item.find('.csv') is not -1 :        \n",
    "        items.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(items)) :\n",
    "    \n",
    "    item = items[i]\n",
    "    df = pd.read_csv(item, engine = 'python').iloc[:,1:]\n",
    "    df.columns = [items[i]]\n",
    "    \n",
    "    if i == 0 :\n",
    "        corr_df = pd.DataFrame()\n",
    "        \n",
    "    corr_df = pd.concat([corr_df, df], axis = 1)\n",
    "\n",
    "    \n",
    "corr = np.array(corr_df.corr().mean(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = []\n",
    "\n",
    "for i in range(0, len(items)) :\n",
    "    score = items[i].split('=')[-1][:6]\n",
    "    score = score.split('.')[0]\n",
    "    score = float(score)\n",
    "    rmse.append(score)\n",
    "    \n",
    "df = pd.DataFrame({'rnk': list(range(0, len(rmse))), 'rmse': rmse, 'cor': corr})\n",
    "df.index = items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('cor', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "g = sns.scatterplot(x=\"cor\", y=\"rmse\", data=df, s=30)\n",
    "\n",
    "for line in range(0, df.shape[0]):\n",
    "     g.text(df.cor[line]+0.00005 , df.rmse[line]-0.00003, \n",
    "            df.rnk[line], horizontalalignment='left', \n",
    "            size='medium', color='black', weight='semibold')\n",
    "        \n",
    "plt.xlim((df.cor.min()-0.00002,df.cor.max()+0.0002))\n",
    "plt.ylim((df.rmse.min()-0.0002,df.rmse.max()+0.0002))\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 멱평균"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블은 별도의 jupyter 파일에서 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 첫 번 째 조합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ensemble_1 폴더를 만든 후 lgbm0=229.csv, rf4=231.csv를 위치시킨다.\n",
    "* 두 파일을 멱평균을 실시한다. \n",
    "* p값은 21.2로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('Ensemble_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`경로를 위치시킨다.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = 'C:\\\\Users\\\\yena1\\\\Desktop\\\\3rd_Solution\\\\'\n",
    "destination_folder = 'C:\\\\Users\\\\yena1\\\\Desktop\\\\3rd_Solution\\\\Ensemble_1\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(source_files + 'lgbm0=229.csv', destination_folder + 'lgbm0=229.csv')\n",
    "shutil.move(source_files + 'rf4=231.csv', destination_folder + 'rf4=231.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### 두 번 째 조합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* Ensemble_2 폴더를 만든 후 rf1=234.csv, rf3=236.csv를 위치시킨다.\n",
    "* 두 파일을 멱평균을 실시한다. \n",
    "* p값은 21.2로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "os.mkdir('Ensemble_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "source_files = 'C:\\\\Users\\\\yena1\\\\Desktop\\\\3rd_solution\\\\'\n",
    "destination_folder = 'C:\\\\Users\\\\yena1\\\\Desktop\\\\3rd_solution\\\\Ensemble_2\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shutil.move(source_files + 'rf1=234.csv', destination_folder + 'rf1=234.csv')\n",
    "shutil.move(source_files + 'rf3=236.csv', destination_folder + 'rf3=236.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과 및 제언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion & Discussion"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "1126_코드정리(+승희, 채연 피쳐 추가).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "341.313px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
